{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c24777-b341-4da9-956a-b0dcc9ec8530",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hybridmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, StandardScaler\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhybridmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HybridClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hybridmodels'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from hybridmodels.classifier import HybridClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb562-2a01-4f55-87b5-a55ff2b12c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_path = \"Crop_Prediction_Dataset.csv\" \n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2976c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"Crop_Prediction_Dataset.csv\" \n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Inspect the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing Values:\\n\", missing_values)\n",
    "\n",
    "# Visualize missing values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap=\"viridis\")\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Data visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Crop Type', data=df)\n",
    "plt.title(\"Distribution of Crop Types\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Pairplot\n",
    "sns.pairplot(df, hue='Crop Type', diag_kind='kde')\n",
    "plt.show()\n",
    "\n",
    "# Data preprocessing\n",
    "# Selecting features and target\n",
    "X = df[['Temperature (Â°C)', 'Humidity (%)', 'Rainfall (mm)', 'Wind Speed (m/s)']]\n",
    "y = df['Crop Type']\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Hybrid Classifier\n",
    "model = HybridClassifier(\n",
    "    models=[\"RandomForest\", \"LogisticRegression\", \"XGBClassifier\"],  # Use multiple models\n",
    "    meta_model=\"LogisticRegression\"  # Meta model to combine predictions\n",
    ")\n",
    "\n",
    "# Train the hybrid model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Output results\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion matrix visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Feature importance for RandomForest\n",
    "if \"RandomForest\" in model.models:\n",
    "    rf_model = model.models[\"RandomForest\"]\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "    features = X.columns\n",
    "    importance_df = pd.DataFrame({\"Feature\": features, \"Importance\": feature_importances}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df, palette=\"viridis\")\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame({\"Actual\": label_encoder.inverse_transform(y_test), \"Predicted\": label_encoder.inverse_transform(y_pred)})\n",
    "results_df.to_csv(\"prediction_results.csv\", index=False)\n",
    "print(\"Prediction results saved to 'prediction_results.csv'.\")\n",
    "\n",
    "# Save preprocessing objects for deployment\n",
    "import joblib\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "print(\"Scaler and Label Encoder saved for future use.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
